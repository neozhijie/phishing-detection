{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87368ba0-0271-4358-88ca-c4376915afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in d:\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: tensorflow in d:\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: keras-tuner in d:\\anaconda3\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: kt-legacy in d:\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: rich in d:\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.9.2)\n",
      "Requirement already satisfied: namex in d:\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib seaborn scikit-learn tensorflow keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae931fff-a074-4a5f-a1c1-e18736172a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a seed value for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# 1. Set the PYTHONHASHSEED environment variable for Python hash-based operations\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# 2. Set the Python built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed)\n",
    "\n",
    "# 3. Set the NumPy pseudo-random generator at a fixed value\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 4. Set the TensorFlow pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d368793c-3fe5-476c-abf0-5cc54b7a4a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Keras Tuner version: 1.4.7\n"
     ]
    }
   ],
   "source": [
    "# Import Required Packages\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For performance metrics\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, classification_report, \n",
    "                             confusion_matrix)\n",
    "\n",
    "# For building the neural network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, Flatten, Dense, Dropout, \n",
    "                                     BatchNormalization)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# For hyperparameter tuning\n",
    "import keras_tuner as kt\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# =============================================\n",
    "# Version Information (Optional)\n",
    "# =============================================\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'Keras Tuner version: {kt.__version__}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515ec0fe-68b1-459b-8ef5-3b76d3c5de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neo_z\\AppData\\Local\\Temp\\ipykernel_50540\\1059801022.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv('dataset_phishing.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['shortest_word_path', 'ratio_intMedia', 'links_in_tags',\n",
    "            'nb_hyphens', 'page_rank', 'avg_word_path', \n",
    "            'ratio_extHyperlinks', 'longest_words_raw', 'google_index',\n",
    "            'length_hostname', 'longest_word_host', \n",
    "            'domain_registration_length', 'nb_www', 'nb_underscore', \n",
    "            'nb_dots', 'ratio_extMedia', 'phish_hints', 'domain_in_title', \n",
    "            'web_traffic', 'safe_anchor', 'nb_space', 'shortening_service', \n",
    "            'ip', 'domain_age', 'nb_qm', 'nb_hyperlinks', 'nb_slash']\n",
    "\n",
    "X = data[features]\n",
    "y = data['status']  # 'status' is 'legitimate' or 'phishing'\n",
    "\n",
    "# Map the 'status' to numerical labels\n",
    "label_mapping = {'legitimate': 0, 'phishing': 1}\n",
    "y = y.map(label_mapping)\n",
    "\n",
    "# Check for any unmapped values or missing values\n",
    "if y.isnull().any():\n",
    "    print(\"Some 'status' values were not mapped properly. Please check the 'status' column for unexpected values.\")\n",
    "    print(y[y.isnull()])\n",
    "\n",
    "\n",
    "# Handle missing values in features if any\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=seed, stratify=y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape data to be suitable for Conv1D (samples, timesteps, features)\n",
    "# Since we have numerical features, we treat each feature as a \"time step\"\n",
    "X_train_cnn = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f9f76a-c5d7-4d23-8749-93d48d14f51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 13s]\n",
      "val_accuracy: 0.9633679389953613\n",
      "\n",
      "Best val_accuracy So Far: 0.96555495262146\n",
      "Total elapsed time: 00h 07m 33s\n",
      "\n",
      "The hyperparameter search is complete. \n",
      "The optimal number of filters in the first Conv1D layer is 48, \n",
      "kernel size is 4, \n",
      "and the learning rate is 0.0017529957488324514.\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3162 - val_accuracy: 0.9060 - val_loss: 0.2940\n",
      "Epoch 2/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1753 - val_accuracy: 0.9584 - val_loss: 0.1454\n",
      "Epoch 3/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.1634 - val_accuracy: 0.9584 - val_loss: 0.1268\n",
      "Epoch 4/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1450 - val_accuracy: 0.9584 - val_loss: 0.1247\n",
      "Epoch 5/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1360 - val_accuracy: 0.9568 - val_loss: 0.1258\n",
      "Epoch 6/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1295 - val_accuracy: 0.9563 - val_loss: 0.1307\n",
      "Epoch 7/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1259 - val_accuracy: 0.9563 - val_loss: 0.1222\n",
      "Epoch 8/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1192 - val_accuracy: 0.9546 - val_loss: 0.1263\n",
      "Epoch 9/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1159 - val_accuracy: 0.9574 - val_loss: 0.1276\n",
      "Epoch 10/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1109 - val_accuracy: 0.9623 - val_loss: 0.1209\n",
      "Epoch 11/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1096 - val_accuracy: 0.9623 - val_loss: 0.1230\n",
      "Epoch 12/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1031 - val_accuracy: 0.9595 - val_loss: 0.1247\n",
      "Epoch 13/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1005 - val_accuracy: 0.9606 - val_loss: 0.1247\n",
      "Epoch 14/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0946 - val_accuracy: 0.9584 - val_loss: 0.1246\n",
      "Epoch 15/50\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0950 - val_accuracy: 0.9628 - val_loss: 0.1273\n"
     ]
    }
   ],
   "source": [
    "# Model Building and Hyperparameter Tuning\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Conv1D layer\n",
    "    model.add(Conv1D(\n",
    "        filters=hp.Int('filters_1', min_value=16, max_value=128, step=16),\n",
    "        kernel_size=hp.Int('kernel_size_1', min_value=2, max_value=5, step=1),\n",
    "        activation='relu',\n",
    "        input_shape=(X_train_cnn.shape[1], 1),\n",
    "        padding='same'\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(hp.Float('dropout_rate_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Optional second Conv1D layer\n",
    "    if hp.Boolean('second_conv_layer'):\n",
    "        model.add(Conv1D(\n",
    "            filters=hp.Int('filters_2', min_value=16, max_value=128, step=16),\n",
    "            kernel_size=hp.Int('kernel_size_2', min_value=2, max_value=5, step=1),\n",
    "            activation='relu',\n",
    "            padding='same'\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Dropout(hp.Float('dropout_rate_2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense layers\n",
    "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
    "        model.add(Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(hp.Float(f'dropout_rate_dense_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuning',\n",
    "    project_name='cnn',\n",
    "    seed=seed, \n",
    "    overwrite=True  \n",
    ")\n",
    "\n",
    "# Early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(\n",
    "    x=X_train_cnn,\n",
    "    y=y_train,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of filters in the first Conv1D layer is {best_hps.get('filters_1')}, \n",
    "kernel size is {best_hps.get('kernel_size_1')}, \n",
    "and the learning rate is {best_hps.get('lr')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1 \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b444036-2e55-409a-b25e-9bec8009b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1256\n",
      "Test Accuracy: 0.9532\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Model Performance Metrics:\n",
      "--------------------------\n",
      "Accuracy  : 0.9532\n",
      "Precision : 0.9536\n",
      "Recall    : 0.9528\n",
      "F1 Score  : 0.9532\n",
      "ROC AUC   : 0.9881\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1090   53]\n",
      " [  54 1089]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1143\n",
      "           1       0.95      0.95      0.95      1143\n",
      "\n",
      "    accuracy                           0.95      2286\n",
      "   macro avg       0.95      0.95      0.95      2286\n",
      "weighted avg       0.95      0.95      0.95      2286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = best_model.evaluate(X_test_cnn, y_test)\n",
    "print('Test Accuracy: {:.4f}'.format(test_acc))\n",
    "\n",
    "# Predict probabilities and classes\n",
    "y_pred_proba = best_model.predict(X_test_cnn).ravel()\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print('\\nModel Performance Metrics:')\n",
    "print('--------------------------')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1))\n",
    "print('ROC AUC   : {:.4f}'.format(roc_auc))\n",
    "\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5a681-c911-4a54-9e4d-4180f4a92786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
