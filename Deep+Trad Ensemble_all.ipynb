{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21713fe-350e-4496-a3f2-42e00b5d2b34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b21713fe-350e-4496-a3f2-42e00b5d2b34",
    "outputId": "2dd3bf2c-e199-4e42-e491-2ef5d8218f26"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix)\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Dropout, Embedding, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras_tuner.tuners import GridSearch\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba96cb86-2241-411e-a1ba-5a18f403a1e2",
   "metadata": {
    "id": "ba96cb86-2241-411e-a1ba-5a18f403a1e2"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8534172-e4e8-49b0-9963-1c67c9eb64dd",
   "metadata": {
    "id": "d8534172-e4e8-49b0-9963-1c67c9eb64dd"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('dataset_phishing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340a12f7-8cc3-4fa9-9cbb-400ea00937ab",
   "metadata": {
    "id": "340a12f7-8cc3-4fa9-9cbb-400ea00937ab"
   },
   "outputs": [],
   "source": [
    "#Top 27 features from feature selection\n",
    "features = ['shortest_word_path',\n",
    " 'ratio_intMedia',\n",
    " 'links_in_tags',\n",
    " 'nb_hyphens',\n",
    " 'page_rank',\n",
    " 'avg_word_path',\n",
    " 'ratio_extHyperlinks',\n",
    " 'longest_words_raw',\n",
    " 'google_index',\n",
    " 'length_hostname',\n",
    " 'longest_word_host',\n",
    " 'domain_registration_length',\n",
    " 'nb_www',\n",
    " 'nb_underscore',\n",
    " 'nb_dots',\n",
    " 'ratio_extMedia',\n",
    " 'phish_hints',\n",
    " 'domain_in_title',\n",
    " 'web_traffic',\n",
    " 'safe_anchor',\n",
    " 'nb_space',\n",
    " 'shortening_service',\n",
    " 'ip',\n",
    " 'domain_age',\n",
    " 'nb_qm',\n",
    " 'nb_hyperlinks',\n",
    " 'nb_slash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f1aca2-38b1-4d2b-83fe-cc10c586e597",
   "metadata": {
    "id": "11f1aca2-38b1-4d2b-83fe-cc10c586e597"
   },
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"status\"])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp= train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape for CNN\n",
    "X_train_cnn = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_val_cnn = X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bb3758-d50f-4d5a-9eb4-117dd75605e8",
   "metadata": {
    "id": "e9bb3758-d50f-4d5a-9eb4-117dd75605e8"
   },
   "outputs": [],
   "source": [
    "def create_model(filters_1=32, kernel_size_1=3, dropout_rate_1=0.2,\n",
    "                 filters_2=64, kernel_size_2=3, dropout_rate_2=0.2,\n",
    "                 dense_units=128, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Conv1D layer\n",
    "    model.add(Conv1D(filters=filters_1, kernel_size=kernel_size_1,\n",
    "                     activation='relu', input_shape=(X_train_cnn.shape[1], 1),\n",
    "                     padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate_1))\n",
    "    \n",
    "    # Second Conv1D layer\n",
    "    model.add(Conv1D(filters=filters_2, kernel_size=kernel_size_2,\n",
    "                     activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate_2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3e3823-be4a-4d2e-9a3f-e15f2df38d79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "ea3e3823-be4a-4d2e-9a3f-e15f2df38d79",
    "outputId": "2dc7cc3c-c556-485c-95e9-222674b114ef"
   },
   "outputs": [],
   "source": [
    "# ## For grid search, skip this and run cell below this to use the parameters obtained from previous grid search result.\n",
    "\n",
    "# # Wrap the model\n",
    "# model = KerasClassifier(\n",
    "#     model=create_model,\n",
    "#     verbose=0,\n",
    "#     random_state=seed\n",
    "# )\n",
    "\n",
    "# # Define the grid search parameters\n",
    "# param_grid = {\n",
    "#     'model__filters_1': [32, 64],\n",
    "#     'model__kernel_size_1': [2, 3],\n",
    "#     'model__dropout_rate_1': [0.2, 0.3],\n",
    "#     'model__filters_2': [32, 64],\n",
    "#     'model__kernel_size_2': [2, 3],\n",
    "#     'model__dropout_rate_2': [0.2, 0.3],\n",
    "#     'model__dense_units': [64, 128],\n",
    "#     'model__learning_rate': [0.001, 0.01]\n",
    "# }\n",
    "\n",
    "# # Create GridSearchCV object\n",
    "# grid = GridSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='recall',\n",
    "#     cv=3,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # Fit the grid search\n",
    "# print(\"Starting Grid Search...\")\n",
    "# grid_result = grid.fit(X_train_cnn, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"\\nBest parameters found:\")\n",
    "# # Remove 'model__' prefix from parameter names for clarity\n",
    "# best_params = {k.replace('model__', ''): v for k, v in grid_result.best_params_.items()}\n",
    "# print(best_params)\n",
    "# print(\"\\nBest recall score:\", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9005f48a-66e4-46fb-908e-523a9407edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'dense_units': 64, 'dropout_rate_1': 0.2, 'dropout_rate_2': 0.2, 'filters_1': 32, 'filters_2': 64, 'kernel_size_1': 3, 'kernel_size_2': 2, 'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5699a80-ed7d-4067-a9e7-2b20c8b12274",
   "metadata": {
    "id": "f5699a80-ed7d-4067-a9e7-2b20c8b12274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final model with best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\testing\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8992 - loss: 0.2736 - recall: 0.8864 - val_accuracy: 0.9113 - val_loss: 0.2300 - val_recall: 0.8471\n",
      "Epoch 2/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1908 - recall: 0.9218 - val_accuracy: 0.9376 - val_loss: 0.1649 - val_recall: 0.9160\n",
      "Epoch 3/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1739 - recall: 0.9281 - val_accuracy: 0.9417 - val_loss: 0.1571 - val_recall: 0.9312\n",
      "Epoch 4/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.1635 - recall: 0.9372 - val_accuracy: 0.9475 - val_loss: 0.1548 - val_recall: 0.9510\n",
      "Epoch 5/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1566 - recall: 0.9384 - val_accuracy: 0.9399 - val_loss: 0.1609 - val_recall: 0.9312\n",
      "Epoch 6/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1463 - recall: 0.9434 - val_accuracy: 0.9457 - val_loss: 0.1543 - val_recall: 0.9498\n",
      "Epoch 7/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.1397 - recall: 0.9435 - val_accuracy: 0.9405 - val_loss: 0.1551 - val_recall: 0.9265\n",
      "Epoch 8/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1381 - recall: 0.9447 - val_accuracy: 0.9463 - val_loss: 0.1515 - val_recall: 0.9522\n",
      "Epoch 9/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1298 - recall: 0.9528 - val_accuracy: 0.9446 - val_loss: 0.1623 - val_recall: 0.9370\n",
      "Epoch 10/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1287 - recall: 0.9474 - val_accuracy: 0.9452 - val_loss: 0.1583 - val_recall: 0.9510\n",
      "Epoch 11/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1230 - recall: 0.9518 - val_accuracy: 0.9481 - val_loss: 0.1481 - val_recall: 0.9498\n",
      "Epoch 12/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1192 - recall: 0.9532 - val_accuracy: 0.9463 - val_loss: 0.1511 - val_recall: 0.9452\n",
      "Epoch 13/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1179 - recall: 0.9518 - val_accuracy: 0.9417 - val_loss: 0.1588 - val_recall: 0.9603\n",
      "Epoch 14/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1127 - recall: 0.9556 - val_accuracy: 0.9417 - val_loss: 0.1618 - val_recall: 0.9312\n",
      "Epoch 15/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1119 - recall: 0.9533 - val_accuracy: 0.9428 - val_loss: 0.1669 - val_recall: 0.9510\n",
      "Epoch 16/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1091 - recall: 0.9613 - val_accuracy: 0.9469 - val_loss: 0.1564 - val_recall: 0.9452\n",
      "Epoch 17/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1042 - recall: 0.9596 - val_accuracy: 0.9457 - val_loss: 0.1561 - val_recall: 0.9370\n",
      "Epoch 18/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1003 - recall: 0.9606 - val_accuracy: 0.9393 - val_loss: 0.1700 - val_recall: 0.9335\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create and train the model with best parameters\n",
    "print(\"\\nTraining final model with best parameters...\")\n",
    "CNN_model = create_model(**best_params)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_recall', patience=5, \n",
    "                             restore_best_weights=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = CNN_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_val_pred_cnn = CNN_model.predict(X_val_cnn)\n",
    "y_test_pred_cnn = CNN_model.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24590f62-8ad7-4d97-b5f8-f91e9a9c6b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\testing\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\testing\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance by oversampling the minority class (phishing)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the MLPClassifier with early stopping to avoid overfitting\n",
    "mlp = MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1, activation='tanh', alpha=0.0006, hidden_layer_sizes=(100,50),\n",
    "                    learning_rate='constant',learning_rate_init=0.008,solver='sgd')\n",
    "\n",
    "# # Set up hyperparameter grid for tuning\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(200, 100)],\n",
    "#     'activation': ['relu', 'tanh', 'logistic'],\n",
    "#     'solver': ['adam', 'sgd'],\n",
    "#     'alpha': [0.0001],\n",
    "#     'learning_rate': ['constant', 'adaptive'],\n",
    "#     'learning_rate_init': [0.008],\n",
    "#     # 'max_iter': [10000],\n",
    "#     # 'tol': [1e-4],\n",
    "#     # 'verbose': [True]\n",
    "# }\n",
    "\n",
    "# # Use GridSearchCV to find the best hyperparameters\n",
    "# grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "\n",
    "# grid_search.fit(X_resampled, y_resampled)\n",
    "mlp.fit(X_resampled, y_resampled)\n",
    "# Get the best model from the grid search\n",
    "# best_mlp = grid_search.best_estimator_\n",
    "y_val_pred_mlp = mlp.predict(X_val)\n",
    "y_test_pred_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aba8b67-9fa3-4c1a-a1ed-89edb862bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\testing\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.9104 - loss: 0.3361 - val_accuracy: 0.9426 - val_loss: 0.1558\n",
      "Epoch 2/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9449 - loss: 0.1425 - val_accuracy: 0.9513 - val_loss: 0.1445\n",
      "Epoch 3/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9519 - loss: 0.1263 - val_accuracy: 0.9563 - val_loss: 0.1361\n",
      "Epoch 4/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9586 - loss: 0.1156 - val_accuracy: 0.9576 - val_loss: 0.1332\n",
      "Epoch 5/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9620 - loss: 0.1079 - val_accuracy: 0.9588 - val_loss: 0.1312\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "X = df[features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_reshaped = X_scaled.reshape((X.shape[0],1,X.shape[1]))  \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"status\"])\n",
    "X_train_lstm, X_temp_lstm, y_train_lstm, y_temp_lstm = train_test_split(X_reshaped, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val_lstm, X_test_lstm, y_val_lstm, y_test_lstm = train_test_split(X_temp_lstm, y_temp_lstm, test_size=0.5, random_state=42, stratify=y_temp_lstm)\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(1024, activation='relu',input_shape=(1,X.shape[1]))) \n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# best_model = tuner.get_best_models()[0]\n",
    "# best_hp = tuner.get_best_hyperparameters()[0]\n",
    "# print(best_hp.values)\n",
    "# tuner.results_summary()\n",
    "\n",
    "history = lstm_model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "y_val_pred_lstm = (lstm_model.predict(X_val_lstm) > 0.5)\n",
    "y_test_pred_lstm = (lstm_model.predict(X_test_lstm) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "YahJE9upVT5m",
   "metadata": {
    "id": "YahJE9upVT5m"
   },
   "outputs": [],
   "source": [
    "# ======================================= METHOD 1: SVM ================================\n",
    "# Hyperparameter tuning for SVM\n",
    "# svm_param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "\n",
    "# svm_grid_search = GridSearchCV(SVC(probability=True, random_state=42), svm_param_grid, cv=5)\n",
    "# svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best parameters for SVM\n",
    "# print(\"Best parameters for SVM:\", svm_grid_search.best_params_)\n",
    "\n",
    "# Validate and test the best SVM model\n",
    "# svm_model = svm_grid_search.best_estimator_\n",
    "svm_model = SVC(probability=True, random_state=42, C=10, gamma='scale', kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_val_pred_svm = svm_model.predict(X_val)\n",
    "y_test_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cad7c41-bc71-4338-8ec8-0d4faad5e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================ METHOD 2: Traditional Tree ==================\n",
    "\n",
    "# Hyperparameter tuning for Decision Tree\n",
    "# dt_param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "# }\n",
    "\n",
    "# dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, cv=5)\n",
    "# dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters for Decision Tree\n",
    "# print(\"Best parameters for Decision Tree:\", dt_grid_search.best_params_)\n",
    "\n",
    "# Validate and test the best Decision Tree model\n",
    "# dt_model = dt_grid_search.best_estimator_\n",
    "dt_model = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=10, min_samples_leaf=1, min_samples_split=2)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_val_pred_dt = dt_model.predict(X_val)\n",
    "y_test_pred_dt = dt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9efde963-f14e-4e25-ad5e-124c6a8dca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='manhattan', n_neighbors=16, p=1,\n",
      "                     weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# Define KNN model and hyperparameter grid\n",
    "# knn = KNeighborsClassifier()\n",
    "# param_grid = {\n",
    "#     'n_neighbors': range(1, 21),           # Test k values from 1 to 20\n",
    "#     'weights': ['uniform', 'distance'],    # Uniform or distance-weighted voting\n",
    "#     'metric': ['euclidean', 'manhattan', 'minkowski'],  # Different distance metrics\n",
    "#     'p': [1, 2]                            # Power parameter for Minkowski (p=1 is Manhattan, p=2 is Euclidean)\n",
    "# }\n",
    "\n",
    "# # Perform GridSearchCV with validation set\n",
    "# grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='recall', verbose=1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "# best_knn = grid_search.best_estimator_\n",
    "best_knn = KNeighborsClassifier(n_neighbors=16,metric='manhattan',p=1,weights='distance')\n",
    "best_knn.fit(X_train,y_train)\n",
    "print(best_knn)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_knn = best_knn.predict(X_val)\n",
    "y_test_pred_knn = best_knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d71fa688-2efb-46b9-b86c-76f922730ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Logistic Regression model and a hyperparameter grid for tuning\n",
    "# logreg = LogisticRegression(max_iter=1000)  # Default Logistic Regression\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "#     'solver': ['liblinear', 'lbfgs']  # Solvers\n",
    "# }\n",
    "\n",
    "# # Perform GridSearchCV with validation set\n",
    "# grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='recall', verbose=1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "# best_logreg = grid_search.best_estimator_\n",
    "best_logreg = LogisticRegression(max_iter=1000,C=100,solver='liblinear')\n",
    "best_logreg.fit(X_train, y_train)\n",
    "# print(best_logreg)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_lr = best_logreg.predict(X_val)\n",
    "y_test_pred_lr = best_logreg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9315a131-3380-46b4-8bae-22c179f00d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and hyperparameter grids\n",
    "models = {\n",
    "    'GaussianNB': (GaussianNB(), {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}),\n",
    "    'BernoulliNB': (BernoulliNB(), {'alpha': [0.5, 1.0, 1.5, 2.0], 'binarize': [0.0, 0.5, 1.0]})\n",
    "}\n",
    "gauss = GaussianNB()\n",
    "bern = BernoulliNB(alpha=0.5)\n",
    "gauss.fit(X_train, y_train)\n",
    "bern.fit(X_train, y_train)\n",
    "y_val_pred_gauss = gauss.predict(X_val)\n",
    "y_test_pred_gauss = gauss.predict(X_test)\n",
    "y_val_pred_bern = bern.predict(X_val)\n",
    "y_test_pred_bern = bern.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c793cee-2276-4704-ae65-1b27aec3a7ec",
   "metadata": {
    "id": "8c793cee-2276-4704-ae65-1b27aec3a7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9638\n",
      "Precision: 0.9574\n",
      "Recall:  0.9708\n",
      "F1 Score: 0.9641\n",
      "ROC_AUC Score: 0.9639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       858\n",
      "           1       0.96      0.97      0.96       857\n",
      "\n",
      "    accuracy                           0.96      1715\n",
      "   macro avg       0.96      0.96      0.96      1715\n",
      "weighted avg       0.96      0.96      0.96      1715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_val = np.column_stack((y_val_pred_cnn,y_val_pred_mlp,y_val_pred_svm,y_val_pred_dt,y_val_pred_knn,y_val_pred_lr,\n",
    "                              y_val_pred_gauss,y_val_pred_bern))\n",
    "\n",
    "hybrid_model = LogisticRegression()\n",
    "hybrid_model.fit(stacked_val, y_val)\n",
    "\n",
    "\n",
    "stacked_test =np.column_stack((y_test_pred_cnn,y_test_pred_mlp,y_test_pred_svm,y_test_pred_dt,y_test_pred_knn,y_test_pred_lr,\n",
    "                              y_test_pred_gauss,y_test_pred_bern))\n",
    "\n",
    "final_pred = hybrid_model.predict(stacked_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test,final_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test,final_pred):.4f}\")\n",
    "print(f\"Recall:  {recall_score(y_test,final_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test,final_pred):.4f}\")\n",
    "print(f\"ROC_AUC Score: {roc_auc_score(y_test,final_pred):.4f}\")\n",
    "print(classification_report(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285469c6-292f-4bce-a310-99f6958530a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
