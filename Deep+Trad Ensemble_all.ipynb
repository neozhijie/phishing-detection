{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21713fe-350e-4496-a3f2-42e00b5d2b34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b21713fe-350e-4496-a3f2-42e00b5d2b34",
    "outputId": "2dd3bf2c-e199-4e42-e491-2ef5d8218f26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 16:00:02.366136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 16:00:02.466068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 16:00:02.487916: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 16:00:02.610792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 16:00:03.532599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix)\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Dropout, Embedding, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras_tuner.tuners import GridSearch\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba96cb86-2241-411e-a1ba-5a18f403a1e2",
   "metadata": {
    "id": "ba96cb86-2241-411e-a1ba-5a18f403a1e2"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8534172-e4e8-49b0-9963-1c67c9eb64dd",
   "metadata": {
    "id": "d8534172-e4e8-49b0-9963-1c67c9eb64dd"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('dataset_phishing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340a12f7-8cc3-4fa9-9cbb-400ea00937ab",
   "metadata": {
    "id": "340a12f7-8cc3-4fa9-9cbb-400ea00937ab"
   },
   "outputs": [],
   "source": [
    "#Top 27 features from feature selection\n",
    "features = ['shortest_word_path',\n",
    " 'ratio_intMedia',\n",
    " 'links_in_tags',\n",
    " 'nb_hyphens',\n",
    " 'page_rank',\n",
    " 'avg_word_path',\n",
    " 'ratio_extHyperlinks',\n",
    " 'longest_words_raw',\n",
    " 'google_index',\n",
    " 'length_hostname',\n",
    " 'longest_word_host',\n",
    " 'domain_registration_length',\n",
    " 'nb_www',\n",
    " 'nb_underscore',\n",
    " 'nb_dots',\n",
    " 'ratio_extMedia',\n",
    " 'phish_hints',\n",
    " 'domain_in_title',\n",
    " 'web_traffic',\n",
    " 'safe_anchor',\n",
    " 'nb_space',\n",
    " 'shortening_service',\n",
    " 'ip',\n",
    " 'domain_age',\n",
    " 'nb_qm',\n",
    " 'nb_hyperlinks',\n",
    " 'nb_slash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f1aca2-38b1-4d2b-83fe-cc10c586e597",
   "metadata": {
    "id": "11f1aca2-38b1-4d2b-83fe-cc10c586e597"
   },
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"status\"])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp= train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape for CNN\n",
    "X_train_cnn = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_val_cnn = X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bb3758-d50f-4d5a-9eb4-117dd75605e8",
   "metadata": {
    "id": "e9bb3758-d50f-4d5a-9eb4-117dd75605e8"
   },
   "outputs": [],
   "source": [
    "def create_model(filters_1=32, kernel_size_1=3, dropout_rate_1=0.2,\n",
    "                 filters_2=64, kernel_size_2=3, dropout_rate_2=0.2,\n",
    "                 dense_units=128, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Conv1D layer\n",
    "    model.add(Conv1D(filters=filters_1, kernel_size=kernel_size_1,\n",
    "                     activation='relu', input_shape=(X_train_cnn.shape[1], 1),\n",
    "                     padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate_1))\n",
    "    \n",
    "    # Second Conv1D layer\n",
    "    model.add(Conv1D(filters=filters_2, kernel_size=kernel_size_2,\n",
    "                     activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate_2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3e3823-be4a-4d2e-9a3f-e15f2df38d79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "ea3e3823-be4a-4d2e-9a3f-e15f2df38d79",
    "outputId": "2dc7cc3c-c556-485c-95e9-222674b114ef"
   },
   "outputs": [],
   "source": [
    "# ## For grid search, skip this and run cell below this to use the parameters obtained from previous grid search result.\n",
    "\n",
    "# # Wrap the model\n",
    "# model = KerasClassifier(\n",
    "#     model=create_model,\n",
    "#     verbose=0,\n",
    "#     random_state=seed\n",
    "# )\n",
    "\n",
    "# # Define the grid search parameters\n",
    "# param_grid = {\n",
    "#     'model__filters_1': [32, 64],\n",
    "#     'model__kernel_size_1': [2, 3],\n",
    "#     'model__dropout_rate_1': [0.2, 0.3],\n",
    "#     'model__filters_2': [32, 64],\n",
    "#     'model__kernel_size_2': [2, 3],\n",
    "#     'model__dropout_rate_2': [0.2, 0.3],\n",
    "#     'model__dense_units': [64, 128],\n",
    "#     'model__learning_rate': [0.001, 0.01]\n",
    "# }\n",
    "\n",
    "# # Create GridSearchCV object\n",
    "# grid = GridSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='recall',\n",
    "#     cv=3,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # Fit the grid search\n",
    "# print(\"Starting Grid Search...\")\n",
    "# grid_result = grid.fit(X_train_cnn, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"\\nBest parameters found:\")\n",
    "# # Remove 'model__' prefix from parameter names for clarity\n",
    "# best_params = {k.replace('model__', ''): v for k, v in grid_result.best_params_.items()}\n",
    "# print(best_params)\n",
    "# print(\"\\nBest recall score:\", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9005f48a-66e4-46fb-908e-523a9407edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'dense_units': 64, 'dropout_rate_1': 0.2, 'dropout_rate_2': 0.2, 'filters_1': 32, 'filters_2': 64, 'kernel_size_1': 3, 'kernel_size_2': 2, 'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5699a80-ed7d-4067-a9e7-2b20c8b12274",
   "metadata": {
    "id": "f5699a80-ed7d-4067-a9e7-2b20c8b12274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final model with best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/projectgrps/IS424/IS424G2/jupyterlab-venv-tf-217/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-06 16:00:05.676953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730880008.334276   50229 service.cc:146] XLA service 0x7fe854006ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730880008.334318   50229 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-11-06 16:00:08.392748: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-06 16:00:08.662232: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/251\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8759 - loss: 0.3087 - recall: 0.8666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730880010.853727   50229 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8909 - loss: 0.2752 - recall: 0.8828 - val_accuracy: 0.9201 - val_loss: 0.2099 - val_recall: 0.8623\n",
      "Epoch 2/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1828 - recall: 0.9222 - val_accuracy: 0.9370 - val_loss: 0.1625 - val_recall: 0.9440\n",
      "Epoch 3/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.1723 - recall: 0.9354 - val_accuracy: 0.9440 - val_loss: 0.1530 - val_recall: 0.9568\n",
      "Epoch 4/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.1581 - recall: 0.9408 - val_accuracy: 0.9422 - val_loss: 0.1549 - val_recall: 0.9370\n",
      "Epoch 5/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1521 - recall: 0.9410 - val_accuracy: 0.9405 - val_loss: 0.1510 - val_recall: 0.9370\n",
      "Epoch 6/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1473 - recall: 0.9388 - val_accuracy: 0.9434 - val_loss: 0.1494 - val_recall: 0.9300\n",
      "Epoch 7/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1397 - recall: 0.9415 - val_accuracy: 0.9457 - val_loss: 0.1474 - val_recall: 0.9393\n",
      "Epoch 8/50\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1361 - recall: 0.9477 - val_accuracy: 0.9376 - val_loss: 0.1572 - val_recall: 0.9300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step \n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create and train the model with best parameters\n",
    "print(\"\\nTraining final model with best parameters...\")\n",
    "CNN_model = create_model(**best_params)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_recall', patience=5, \n",
    "                             restore_best_weights=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = CNN_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_val_pred_cnn = CNN_model.predict(X_val_cnn)\n",
    "y_test_pred_cnn = CNN_model.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24590f62-8ad7-4d97-b5f8-f91e9a9c6b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/projectgrps/IS424/IS424G2/jupyterlab-venv-tf-217/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/common/home/projectgrps/IS424/IS424G2/jupyterlab-venv-tf-217/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance by oversampling the minority class (phishing)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the MLPClassifier with early stopping to avoid overfitting\n",
    "mlp = MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1, activation='tanh', alpha=0.0006, hidden_layer_sizes=(100,50),\n",
    "                    learning_rate='constant',learning_rate_init=0.008,solver='sgd')\n",
    "\n",
    "# # Set up hyperparameter grid for tuning\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(200, 100)],\n",
    "#     'activation': ['relu', 'tanh', 'logistic'],\n",
    "#     'solver': ['adam', 'sgd'],\n",
    "#     'alpha': [0.0001],\n",
    "#     'learning_rate': ['constant', 'adaptive'],\n",
    "#     'learning_rate_init': [0.008],\n",
    "#     # 'max_iter': [10000],\n",
    "#     # 'tol': [1e-4],\n",
    "#     # 'verbose': [True]\n",
    "# }\n",
    "\n",
    "# # Use GridSearchCV to find the best hyperparameters\n",
    "# grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "\n",
    "# grid_search.fit(X_resampled, y_resampled)\n",
    "mlp.fit(X_resampled, y_resampled)\n",
    "# Get the best model from the grid search\n",
    "# best_mlp = grid_search.best_estimator_\n",
    "y_val_pred_mlp = mlp.predict(X_val)\n",
    "y_test_pred_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aba8b67-9fa3-4c1a-a1ed-89edb862bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/projectgrps/IS424/IS424G2/jupyterlab-venv-tf-217/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 16:00:23.502696: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_50', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-11-06 16:00:24.288524: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_50', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-11-06 16:00:24.982498: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_50', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2024-11-06 16:00:25.140867: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_50', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9142 - loss: 0.3356 - val_accuracy: 0.9426 - val_loss: 0.1563\n",
      "Epoch 2/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.9451 - loss: 0.1428 - val_accuracy: 0.9513 - val_loss: 0.1444\n",
      "Epoch 3/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9526 - loss: 0.1266 - val_accuracy: 0.9563 - val_loss: 0.1369\n",
      "Epoch 4/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9589 - loss: 0.1156 - val_accuracy: 0.9600 - val_loss: 0.1327\n",
      "Epoch 5/5\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9619 - loss: 0.1076 - val_accuracy: 0.9588 - val_loss: 0.1320\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step \n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n"
     ]
    }
   ],
   "source": [
    "X = df[features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_reshaped = X_scaled.reshape((X.shape[0],1,X.shape[1]))  \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"status\"])\n",
    "X_train_lstm, X_temp_lstm, y_train_lstm, y_temp_lstm = train_test_split(X_reshaped, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val_lstm, X_test_lstm, y_val_lstm, y_test_lstm = train_test_split(X_temp_lstm, y_temp_lstm, test_size=0.5, random_state=42, stratify=y_temp_lstm)\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(1024, activation='relu',input_shape=(1,X.shape[1]))) \n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# best_model = tuner.get_best_models()[0]\n",
    "# best_hp = tuner.get_best_hyperparameters()[0]\n",
    "# print(best_hp.values)\n",
    "# tuner.results_summary()\n",
    "\n",
    "history = lstm_model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "y_val_pred_lstm = (lstm_model.predict(X_val_lstm) > 0.5)\n",
    "y_test_pred_lstm = (lstm_model.predict(X_test_lstm) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "YahJE9upVT5m",
   "metadata": {
    "id": "YahJE9upVT5m"
   },
   "outputs": [],
   "source": [
    "# ======================================= METHOD 1: SVM ================================\n",
    "# Hyperparameter tuning for SVM\n",
    "# svm_param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "\n",
    "# svm_grid_search = GridSearchCV(SVC(probability=True, random_state=42), svm_param_grid, cv=5)\n",
    "# svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best parameters for SVM\n",
    "# print(\"Best parameters for SVM:\", svm_grid_search.best_params_)\n",
    "\n",
    "# Validate and test the best SVM model\n",
    "# svm_model = svm_grid_search.best_estimator_\n",
    "svm_model = SVC(probability=True, random_state=42, C=10, gamma='scale', kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_val_pred_svm = svm_model.predict(X_val)\n",
    "y_test_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cad7c41-bc71-4338-8ec8-0d4faad5e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================ METHOD 2: Traditional Tree ==================\n",
    "\n",
    "# Hyperparameter tuning for Decision Tree\n",
    "# dt_param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "# }\n",
    "\n",
    "# dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, cv=5)\n",
    "# dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters for Decision Tree\n",
    "# print(\"Best parameters for Decision Tree:\", dt_grid_search.best_params_)\n",
    "\n",
    "# Validate and test the best Decision Tree model\n",
    "# dt_model = dt_grid_search.best_estimator_\n",
    "dt_model = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=10, min_samples_leaf=1, min_samples_split=2)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_val_pred_dt = dt_model.predict(X_val)\n",
    "y_test_pred_dt = dt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9efde963-f14e-4e25-ad5e-124c6a8dca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='manhattan', n_neighbors=16, p=1,\n",
      "                     weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# Define KNN model and hyperparameter grid\n",
    "# knn = KNeighborsClassifier()\n",
    "# param_grid = {\n",
    "#     'n_neighbors': range(1, 21),           # Test k values from 1 to 20\n",
    "#     'weights': ['uniform', 'distance'],    # Uniform or distance-weighted voting\n",
    "#     'metric': ['euclidean', 'manhattan', 'minkowski'],  # Different distance metrics\n",
    "#     'p': [1, 2]                            # Power parameter for Minkowski (p=1 is Manhattan, p=2 is Euclidean)\n",
    "# }\n",
    "\n",
    "# # Perform GridSearchCV with validation set\n",
    "# grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='recall', verbose=1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "# best_knn = grid_search.best_estimator_\n",
    "best_knn = KNeighborsClassifier(n_neighbors=16,metric='manhattan',p=1,weights='distance')\n",
    "best_knn.fit(X_train,y_train)\n",
    "print(best_knn)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_knn = best_knn.predict(X_val)\n",
    "y_test_pred_knn = best_knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d71fa688-2efb-46b9-b86c-76f922730ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Logistic Regression model and a hyperparameter grid for tuning\n",
    "# logreg = LogisticRegression(max_iter=1000)  # Default Logistic Regression\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "#     'solver': ['liblinear', 'lbfgs']  # Solvers\n",
    "# }\n",
    "\n",
    "# # Perform GridSearchCV with validation set\n",
    "# grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='recall', verbose=1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "# best_logreg = grid_search.best_estimator_\n",
    "best_logreg = LogisticRegression(max_iter=1000,C=100,solver='liblinear')\n",
    "best_logreg.fit(X_train, y_train)\n",
    "# print(best_logreg)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_lr = best_logreg.predict(X_val)\n",
    "y_test_pred_lr = best_logreg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9315a131-3380-46b4-8bae-22c179f00d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and hyperparameter grids\n",
    "models = {\n",
    "    'GaussianNB': (GaussianNB(), {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}),\n",
    "    'BernoulliNB': (BernoulliNB(), {'alpha': [0.5, 1.0, 1.5, 2.0], 'binarize': [0.0, 0.5, 1.0]})\n",
    "}\n",
    "gauss = GaussianNB()\n",
    "bern = BernoulliNB(alpha=0.5)\n",
    "gauss.fit(X_train, y_train)\n",
    "bern.fit(X_train, y_train)\n",
    "y_val_pred_gauss = gauss.predict(X_val)\n",
    "y_test_pred_gauss = gauss.predict(X_test)\n",
    "y_val_pred_bern = bern.predict(X_val)\n",
    "y_test_pred_bern = bern.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c793cee-2276-4704-ae65-1b27aec3a7ec",
   "metadata": {
    "id": "8c793cee-2276-4704-ae65-1b27aec3a7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9609\n",
      "Precision: 0.9551\n",
      "Recall:  0.9673\n",
      "F1 Score: 0.9612\n",
      "ROC_AUC Score: 0.9609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       858\n",
      "           1       0.96      0.97      0.96       857\n",
      "\n",
      "    accuracy                           0.96      1715\n",
      "   macro avg       0.96      0.96      0.96      1715\n",
      "weighted avg       0.96      0.96      0.96      1715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_val = np.column_stack((y_val_pred_cnn,y_val_pred_mlp,y_val_pred_svm,y_val_pred_dt,y_val_pred_knn,y_val_pred_lr,\n",
    "                              y_val_pred_gauss,y_val_pred_bern))\n",
    "\n",
    "hybrid_model = LogisticRegression()\n",
    "hybrid_model.fit(stacked_val, y_val)\n",
    "\n",
    "\n",
    "stacked_test =np.column_stack((y_test_pred_cnn,y_test_pred_mlp,y_test_pred_svm,y_test_pred_dt,y_test_pred_knn,y_test_pred_lr,\n",
    "                              y_test_pred_gauss,y_test_pred_bern))\n",
    "\n",
    "final_pred = hybrid_model.predict(stacked_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test,final_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test,final_pred):.4f}\")\n",
    "print(f\"Recall:  {recall_score(y_test,final_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test,final_pred):.4f}\")\n",
    "print(f\"ROC_AUC Score: {roc_auc_score(y_test,final_pred):.4f}\")\n",
    "print(classification_report(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285469c6-292f-4bce-a310-99f6958530a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
